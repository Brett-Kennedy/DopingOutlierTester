{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd332ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import jaccard_score\n",
    "import warnings\n",
    "from scipy.stats import SpearmanRConstantInputWarning\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from outliers_test import DopingOutliersTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13a1511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore', category=SpearmanRConstantInputWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042c992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_colwidth = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.width = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c15be15",
   "metadata": {},
   "source": [
    "### Define a random, large set of datasets from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3398daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_files = [\n",
    "    'soybean',\n",
    "    'micro-mass',\n",
    "    'mfeat-karhunen',\n",
    "    'Amazon_employee_access',\n",
    "    'abalone',\n",
    "    'cnae-9',\n",
    "    'semeion',\n",
    "    'vehicle',\n",
    "    'satimage',\n",
    "    'analcatdata_authorship',\n",
    "    'breast-w',\n",
    "    'SpeedDating',\n",
    "    'eucalyptus',\n",
    "    'isolet',\n",
    "    'bioresponse',\n",
    "    'vowel',\n",
    "    'wall-robot-navigation',\n",
    "    'credit-approval',\n",
    "    'artificial-characters',\n",
    "    'splice',\n",
    "    'har',\n",
    "    'cmc',\n",
    "    'segment',\n",
    "    'JapaneseVowels',\n",
    "    'jm1',\n",
    "    'gas-drift',\n",
    "    'mushroom',\n",
    "    'irish',\n",
    "    'profb',\n",
    "    'adult',\n",
    "    'anneal',\n",
    "    'credit-g',\n",
    "    'blood-transfusion-service-center',\n",
    "    'monks-problems-2',\n",
    "    'tic-tac-toe',\n",
    "    'qsar-biodeg',\n",
    "    'wdbc',\n",
    "    'phoneme',\n",
    "    'diabetes',\n",
    "    'ozone-level-8hr',\n",
    "    'hill-valley',\n",
    "    'kc2',\n",
    "    'eeg-eye-state',\n",
    "    'climate-model-simulation-crashes',\n",
    "    'spambase',\n",
    "    'ilpd',\n",
    "    'one-hundred-plants-margin',\n",
    "    'banknote-authentication',\n",
    "    'mozilla4',\n",
    "    'electricity',\n",
    "    'madelon',\n",
    "    'scene',\n",
    "    'musk',\n",
    "    'nomao',\n",
    "    'MagicTelescope',\n",
    "    'PhishingWebsites',\n",
    "    'nursery',\n",
    "    'page-blocks',\n",
    "    'hypothyroid',\n",
    "    'yeast',\n",
    "    'kropt',\n",
    "    'CreditCardSubset',\n",
    "    'shuttle',\n",
    "    'Satellite',\n",
    "    'baseball',\n",
    "    'mc1',\n",
    "    'pc1',\n",
    "    'cardiotocography',\n",
    "    'kr-vs-k',\n",
    "    'volcanoes-a1',\n",
    "    'wine-quality-white',\n",
    "    'car-evaluation',\n",
    "    'solar-flare',\n",
    "    'allbp',\n",
    "    'allrep',\n",
    "    'dis',\n",
    "    'car',\n",
    "    'steel-plates-fault'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe7f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Encoding is used to encode non-numeric values, required by \n",
    "# IsolationForest and Local Outlier Factor\n",
    "\n",
    "def get_count_encoding(df):\n",
    "    df = df.copy()\n",
    "    for col_name in df.columns:\n",
    "        if df[col_name].dtype.name in ['str', 'category', 'object']:\n",
    "            df[col_name] = df[col_name].astype(str)\n",
    "            vc = df[col_name].value_counts(dropna=False)\n",
    "            df[col_name] = df[col_name].replace([None, np.nan, -np.nan, 'nan'], df[col_name].mode()[0])\n",
    "            map_dict = {x: y for x, y in zip(vc.index, vc.values)}\n",
    "            df[col_name] = df[col_name].map(map_dict)\n",
    "            df[col_name] = df[col_name].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29c8d5",
   "metadata": {},
   "source": [
    "### Quick example with a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06afa6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IF Orig Score</th>\n",
       "      <th>IF Orig Cleaned</th>\n",
       "      <th>IF Modified Score</th>\n",
       "      <th>IF Modified Cleaned</th>\n",
       "      <th>IF Gain</th>\n",
       "      <th>IF Gain Cleaned</th>\n",
       "      <th>OUTLIER SCORE</th>\n",
       "      <th>IF Flagged</th>\n",
       "      <th>Doping Flagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.459975</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655302</td>\n",
       "      <td>0.655302</td>\n",
       "      <td>0.655302</td>\n",
       "      <td>0.655302</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.517290</td>\n",
       "      <td>0.625524</td>\n",
       "      <td>0.625524</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>0.108234</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>0.455054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579018</td>\n",
       "      <td>0.579018</td>\n",
       "      <td>0.579018</td>\n",
       "      <td>0.579018</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>0.619549</td>\n",
       "      <td>0.619549</td>\n",
       "      <td>0.676282</td>\n",
       "      <td>0.676282</td>\n",
       "      <td>0.056734</td>\n",
       "      <td>0.056734</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>0.442317</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>0.520008</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.445890</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>0.546312</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.471750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>0.504285</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.412765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>0.505419</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.466335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522281</td>\n",
       "      <td>0.522281</td>\n",
       "      <td>0.522281</td>\n",
       "      <td>0.522281</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.456063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448085</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.431276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.419568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.466842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.470193</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.446346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.438465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.429089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>0.454992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.434315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     IF Orig Score  IF Orig Cleaned  IF Modified Score  IF Modified Cleaned   IF Gain  IF Gain Cleaned  OUTLIER SCORE  IF Flagged  Doping Flagged\n",
       "559       0.459975         0.000000           0.655302             0.655302  0.655302         0.655302             15        True            True\n",
       "707       0.517290         0.517290           0.625524             0.625524  0.108234         0.108234              8        True            True\n",
       "723       0.455054         0.000000           0.579018             0.579018  0.579018         0.579018              7        True            True\n",
       "835       0.619549         0.619549           0.676282             0.676282  0.056734         0.056734              6        True            True\n",
       "684       0.442317         0.000000           0.520008             0.520008  0.520008         0.520008              6        True            True\n",
       "763       0.445890         0.000000           0.546312             0.546312  0.546312         0.546312              6        True            True\n",
       "629       0.471750         0.000000           0.504285             0.504285  0.504285         0.504285              5        True            True\n",
       "192       0.412765         0.000000           0.505419             0.505419  0.505419         0.505419              4        True            True\n",
       "359       0.466335         0.000000           0.522281             0.522281  0.522281         0.522281              3        True            True\n",
       "9         0.456063         0.000000           0.448085             0.000000  0.000000         0.000000              1       False            True\n",
       "558       0.431276         0.000000           0.419568             0.000000  0.000000         0.000000              0       False           False\n",
       "560       0.466842         0.000000           0.446960             0.000000  0.000000         0.000000              0       False           False\n",
       "566       0.470193         0.000000           0.446346             0.000000  0.000000         0.000000              0       False           False\n",
       "561       0.438465         0.000000           0.429089             0.000000  0.000000         0.000000              0       False           False\n",
       "562       0.454992         0.000000           0.434315             0.000000  0.000000         0.000000              0       False           False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman Correlation: Gain in IF scores to: Estimated Scores:  0.791260814871002\n",
      "Jaccard Similarity: Gain in IF scores to: Estimated Scores:  0.6428571428571429\n",
      "Number rows with increase in IF scores: 13\n"
     ]
    }
   ],
   "source": [
    "# In this example, we use the vehicle dataset from OpenML. We get the \n",
    "# outlier scores of each row using Isolation Forest (IF) before and \n",
    "# after doping the dataset, and check if the IF is able to correctly\n",
    "# give higher scores to the modified rows after vs before doping. \n",
    "\n",
    "# We check the spearman correlation to determine if the specific increase\n",
    "# in IF score has a rank-order correlation with the outlier scores\n",
    "# estimated by the doping process. \n",
    "\n",
    "# We also create binary flags to indicate if the IF flagged each\n",
    "# row and if the row was modifified by the doping process. We check\n",
    "# for overlap in these using the jaccard similarity score. \n",
    "\n",
    "# In this example, both scores perform well, though this is based on\n",
    "# a cut-off for IF scores of 0.5, which will not work for all datasets\n",
    "# and is done here for simplicity.\n",
    "\n",
    "\n",
    "# Collect a single dataset from OpenML\n",
    "data = fetch_openml('vehicle', version=1)\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# Create a doped version of the dataset\n",
    "data_modifier = DopingOutliersTest()\n",
    "df_modified, outlier_scores = data_modifier.transform(df, random_state=0, verbose=False)\n",
    "\n",
    "# Encode the original data in a format usable by IF\n",
    "df_encoded = get_count_encoding(df)\n",
    "df_encoded = df_encoded.fillna(0)\n",
    "df_encoded = df_encoded.replace([np.nan, -np.nan], 0)\n",
    "\n",
    "# Get IsolationForest (IF) scores on original data\n",
    "det = IsolationForest(random_state=0)\n",
    "det.fit(df_encoded)\n",
    "y_orig_if = det.score_samples(df_encoded)\n",
    "\n",
    "# Encode the doped data in a format usable by IF\n",
    "df_modified_encoded = get_count_encoding(df_modified)\n",
    "df_modified_encoded = df_modified_encoded.fillna(0)\n",
    "df_modified_encoded = df_modified_encoded.replace([np.nan, -np.nan], 0)\n",
    "\n",
    "# Get IF scores on modified dataset\n",
    "det = IsolationForest(random_state=0)\n",
    "det.fit(df_modified_encoded)\n",
    "y_modified_if = det.score_samples(df_modified_encoded)\n",
    "\n",
    "# Store the IF results. We clean the IF scores by converting them to a larger-is-more-anomalous\n",
    "# format, and setting any low scores to zero. We then take the difference in IF scores between\n",
    "# the original and doped datasets. Ideally, the doped rows will be flagged as being more \n",
    "# anomalous then their original form. \n",
    "df_modified['IF Orig Score'] = y_orig_if * (-1)\n",
    "df_modified['IF Orig Cleaned'] = df_modified['IF Orig Score'].apply(lambda x: 0 if x <= 0.5 else x)\n",
    "df_modified['IF Modified Score'] = y_modified_if * (-1)\n",
    "df_modified['IF Modified Cleaned'] = df_modified['IF Modified Score'].apply(lambda x: 0 if x <= 0.5 else x)\n",
    "df_modified['IF Gain'] = df_modified['IF Modified Cleaned'] - df_modified['IF Orig Cleaned']\n",
    "df_modified['IF Gain Cleaned'] = df_modified['IF Gain'].apply(lambda x: 0 if x <= 0.0 else x)\n",
    "\n",
    "# Store the outlier score estimated by the doping tool\n",
    "df_modified['OUTLIER SCORE'] = outlier_scores\n",
    "\n",
    "# Add binary columns indicating if IF and the Doping process identified the rows\n",
    "# with any score\n",
    "df_modified['IF Flagged'] = df_modified['IF Gain Cleaned'] > 0\n",
    "df_modified['Doping Flagged'] = df_modified['OUTLIER SCORE'] > 0\n",
    "\n",
    "# Display the results. This just shows the 10 rows that were modified as well as 5 other rows.\n",
    "display(df_modified[[\n",
    "    'IF Orig Score',\n",
    "    'IF Orig Cleaned',\n",
    "    'IF Modified Score',\n",
    "    'IF Modified Cleaned',\n",
    "    'IF Gain',\n",
    "    'IF Gain Cleaned',\n",
    "    'OUTLIER SCORE',\n",
    "    'IF Flagged',\n",
    "    'Doping Flagged'\n",
    "    ]].sort_values(['OUTLIER SCORE'], ascending=False).head(15))\n",
    "\n",
    "# Print the correlations\n",
    "print(\"Spearman Correlation: Gain in IF scores to: Estimated Scores: \",\n",
    "      scipy.stats.spearmanr(df_modified['IF Gain Cleaned'], df_modified['OUTLIER SCORE'])[0])\n",
    "\n",
    "print(\"Jaccard Similarity: Gain in IF scores to: Estimated Scores: \", \n",
    "      jaccard_score(df_modified['IF Flagged'], df_modified['Doping Flagged']))\n",
    "\n",
    "# Print the number of rows where there is an increase in IF scores. Ideally this will be\n",
    "# close to 10, the actual number modified.\n",
    "print(f\"Number rows with increase in IF scores: {df_modified['IF Flagged'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da21310",
   "metadata": {},
   "source": [
    "### Test Isolation Forest given a doped version of each OpenML dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b19f20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating soybean\n",
      "Evaluating micro-mass\n",
      "Evaluating mfeat-karhunen\n",
      "Evaluating Amazon_employee_access\n",
      "Evaluating abalone\n",
      "Evaluating cnae-9\n",
      "Evaluating semeion\n",
      "Evaluating vehicle\n",
      "Evaluating satimage\n",
      "Evaluating analcatdata_authorship\n",
      "Evaluating breast-w\n",
      "Evaluating SpeedDating\n",
      "Evaluating eucalyptus\n",
      "Evaluating isolet\n",
      "Evaluating bioresponse\n",
      "Evaluating vowel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmbre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\datasets\\_openml.py:849: UserWarning: Version 1 of dataset vowel is inactive, meaning that issues have been found in the dataset. Try using a newer version from this URL: https://api.openml.org/data/v1/download/58/vowel.arff\n",
      "  warn(\"Version {} of dataset {} is inactive, meaning that issues have \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating wall-robot-navigation\n",
      "Evaluating credit-approval\n",
      "Evaluating artificial-characters\n",
      "Evaluating splice\n",
      "Evaluating har\n",
      "Evaluating cmc\n",
      "Evaluating segment\n",
      "Evaluating JapaneseVowels\n",
      "Evaluating jm1\n",
      "Evaluating gas-drift\n",
      "Evaluating mushroom\n",
      "Evaluating irish\n",
      "Evaluating profb\n",
      "Evaluating adult\n",
      "Evaluating anneal\n",
      "Evaluating credit-g\n",
      "Evaluating blood-transfusion-service-center\n",
      "Evaluating monks-problems-2\n",
      "Evaluating tic-tac-toe\n",
      "Evaluating qsar-biodeg\n",
      "Evaluating wdbc\n",
      "Evaluating phoneme\n",
      "Evaluating diabetes\n",
      "Evaluating ozone-level-8hr\n",
      "Evaluating hill-valley\n",
      "Evaluating kc2\n",
      "Evaluating eeg-eye-state\n",
      "Evaluating climate-model-simulation-crashes\n",
      "Evaluating spambase\n",
      "Evaluating ilpd\n",
      "Evaluating one-hundred-plants-margin\n",
      "Evaluating banknote-authentication\n",
      "Evaluating mozilla4\n",
      "Evaluating electricity\n",
      "Evaluating madelon\n",
      "Evaluating scene\n",
      "Evaluating musk\n",
      "Evaluating nomao\n",
      "Evaluating MagicTelescope\n",
      "Evaluating PhishingWebsites\n",
      "Evaluating nursery\n",
      "Evaluating page-blocks\n",
      "Evaluating hypothyroid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmbre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1111: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating yeast\n",
      "Evaluating kropt\n",
      "Evaluating CreditCardSubset\n",
      "Evaluating shuttle\n",
      "Evaluating Satellite\n",
      "Evaluating baseball\n",
      "Evaluating mc1\n",
      "Evaluating pc1\n",
      "Evaluating cardiotocography\n",
      "Evaluating kr-vs-k\n",
      "Evaluating volcanoes-a1\n",
      "Evaluating wine-quality-white\n",
      "Evaluating car-evaluation\n",
      "Evaluating solar-flare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmbre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\datasets\\_openml.py:849: UserWarning: Version 1 of dataset solar-flare is inactive, meaning that issues have been found in the dataset. Try using a newer version from this URL: https://api.openml.org/data/v1/download/3596/solar-flare.arff\n",
      "  warn(\"Version {} of dataset {} is inactive, meaning that issues have \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating allbp\n",
      "Evaluating allrep\n",
      "Evaluating dis\n",
      "Evaluating car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmbre\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\datasets\\_openml.py:849: UserWarning: Version 1 of dataset car is inactive, meaning that issues have been found in the dataset. Try using a newer version from this URL: https://api.openml.org/data/v1/download/21/car.arff\n",
      "  warn(\"Version {} of dataset {} is inactive, meaning that issues have \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating steel-plates-fault\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>IF Spearman Correlation</th>\n",
       "      <th>IF Jaccard Similarity</th>\n",
       "      <th>IF Number Flagged</th>\n",
       "      <th>IF Jaccard Similarity to top 10</th>\n",
       "      <th>IF Jaccard Similarity Given IQR</th>\n",
       "      <th>LOF Spearman Correlation</th>\n",
       "      <th>LOF Jaccard Similarity</th>\n",
       "      <th>LOF Number Flagged</th>\n",
       "      <th>LOF Jaccard Similarity to top 10</th>\n",
       "      <th>LOF Jaccard Similarity Given IQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soybean</td>\n",
       "      <td>0.192750</td>\n",
       "      <td>0.048387</td>\n",
       "      <td>185</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.168080</td>\n",
       "      <td>0.123288</td>\n",
       "      <td>72</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micro-mass</td>\n",
       "      <td>0.227214</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>120</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.211286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mfeat-karhunen</td>\n",
       "      <td>0.121628</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>1025</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.126730</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon_employee_access</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>3689</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.040541</td>\n",
       "      <td>0.023831</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>15441</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abalone</td>\n",
       "      <td>0.084646</td>\n",
       "      <td>0.047847</td>\n",
       "      <td>209</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098596</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>42</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>0.142895</td>\n",
       "      <td>0.020455</td>\n",
       "      <td>439</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.165895</td>\n",
       "      <td>0.059172</td>\n",
       "      <td>169</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>semeion</td>\n",
       "      <td>0.123180</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>501</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.119277</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>5</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>vehicle</td>\n",
       "      <td>0.179932</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>23</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.183321</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>37</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>satimage</td>\n",
       "      <td>0.068252</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>1620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.086692</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.030211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>analcatdata_authorship</td>\n",
       "      <td>0.187523</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>118</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.187748</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>breast-w</td>\n",
       "      <td>0.205701</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.192553</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>126</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SpeedDating</td>\n",
       "      <td>0.036947</td>\n",
       "      <td>0.001898</td>\n",
       "      <td>4212</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.032445</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>559</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>eucalyptus</td>\n",
       "      <td>0.200516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200508</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>38</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>isolet</td>\n",
       "      <td>0.007967</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>2796</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.065933</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.023316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bioresponse</td>\n",
       "      <td>0.078158</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>1039</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.048645</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>11</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vowel</td>\n",
       "      <td>0.172177</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>133</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.174367</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wall-robot-navigation</td>\n",
       "      <td>0.074084</td>\n",
       "      <td>0.003979</td>\n",
       "      <td>2513</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.099429</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>52</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.034247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>credit-approval</td>\n",
       "      <td>0.206280</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.201520</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>60</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>artificial-characters</td>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>3312</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.092191</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>35</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.027190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>splice</td>\n",
       "      <td>0.066489</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>656</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.077076</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>har</td>\n",
       "      <td>0.044569</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>8478</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.062764</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cmc</td>\n",
       "      <td>0.092164</td>\n",
       "      <td>0.017032</td>\n",
       "      <td>408</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.088880</td>\n",
       "      <td>0.013536</td>\n",
       "      <td>589</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>segment</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.015306</td>\n",
       "      <td>587</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.129091</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>43</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JapaneseVowels</td>\n",
       "      <td>0.043891</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>3742</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.073782</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jm1</td>\n",
       "      <td>0.052475</td>\n",
       "      <td>0.003519</td>\n",
       "      <td>2842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.076044</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gas-drift</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>5442</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.101666</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>25</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.042654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mushroom</td>\n",
       "      <td>0.044329</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>4186</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.059980</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>17</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>irish</td>\n",
       "      <td>0.188731</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>152</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.240584</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>67</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>profb</td>\n",
       "      <td>0.209713</td>\n",
       "      <td>0.072993</td>\n",
       "      <td>137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.209710</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>99</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>adult</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>6536</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.007759</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>18169</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>anneal</td>\n",
       "      <td>0.159308</td>\n",
       "      <td>0.029316</td>\n",
       "      <td>306</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.110357</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>86</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>0.108447</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>155</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.126817</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>53</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>blood-transfusion-service-center</td>\n",
       "      <td>0.138383</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.197050</td>\n",
       "      <td>0.150943</td>\n",
       "      <td>51</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>monks-problems-2</td>\n",
       "      <td>0.216964</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>73</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.228506</td>\n",
       "      <td>0.126582</td>\n",
       "      <td>79</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>tic-tac-toe</td>\n",
       "      <td>0.176036</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.176037</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>qsar-biodeg</td>\n",
       "      <td>0.167831</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.174712</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>76</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>wdbc</td>\n",
       "      <td>0.227597</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162705</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>49</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>phoneme</td>\n",
       "      <td>0.059565</td>\n",
       "      <td>0.008443</td>\n",
       "      <td>1065</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.091841</td>\n",
       "      <td>0.140845</td>\n",
       "      <td>71</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>diabetes</td>\n",
       "      <td>0.157496</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.188928</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>31</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ozone-level-8hr</td>\n",
       "      <td>0.091133</td>\n",
       "      <td>0.020179</td>\n",
       "      <td>445</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.088677</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>29</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>hill-valley</td>\n",
       "      <td>0.131258</td>\n",
       "      <td>0.123077</td>\n",
       "      <td>63</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.176629</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>35</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>kc2</td>\n",
       "      <td>0.237648</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151531</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>74</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>eeg-eye-state</td>\n",
       "      <td>0.044736</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>3598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.056412</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>climate-model-simulation-crashes</td>\n",
       "      <td>0.186921</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>27</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.058462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>5</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>spambase</td>\n",
       "      <td>0.080661</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.100461</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>37</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.036232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ilpd</td>\n",
       "      <td>0.224883</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.224807</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>40</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>one-hundred-plants-margin</td>\n",
       "      <td>0.127380</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>250</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.137016</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>banknote-authentication</td>\n",
       "      <td>0.146491</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>22</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.164772</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.163934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mozilla4</td>\n",
       "      <td>0.035138</td>\n",
       "      <td>0.004964</td>\n",
       "      <td>1812</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.058773</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>59</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.018735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>electricity</td>\n",
       "      <td>0.021894</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>35377</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>15472</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.120482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>madelon</td>\n",
       "      <td>0.076949</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>1645</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.107298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>scene</td>\n",
       "      <td>0.084789</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>922</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.107430</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>903</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>musk</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>2792</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.079772</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>21</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>nomao</td>\n",
       "      <td>0.018157</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>22848</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.028980</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>7201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>MagicTelescope</td>\n",
       "      <td>0.039705</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>5835</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.055981</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>40</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.019305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>PhishingWebsites</td>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.001340</td>\n",
       "      <td>5969</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.042719</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>5377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>nursery</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>12001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038221</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>3821</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>page-blocks</td>\n",
       "      <td>0.073969</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>112</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.091999</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>50</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>hypothyroid</td>\n",
       "      <td>0.063677</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>1149</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.063338</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>82</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.029963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>yeast</td>\n",
       "      <td>0.141702</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140163</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>42</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>kropt</td>\n",
       "      <td>0.017036</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>13534</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.032388</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>11220</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>CreditCardSubset</td>\n",
       "      <td>0.037584</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>1235</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>0.071029</td>\n",
       "      <td>0.094340</td>\n",
       "      <td>48</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.026403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>shuttle</td>\n",
       "      <td>0.022741</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>36885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>1570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.188679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Satellite</td>\n",
       "      <td>0.076107</td>\n",
       "      <td>0.008969</td>\n",
       "      <td>1115</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.077430</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>33</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>baseball</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>85</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.149068</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>31</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mc1</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>0.012048</td>\n",
       "      <td>830</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>50</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>pc1</td>\n",
       "      <td>0.163733</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>14</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.151501</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>71</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.059211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>cardiotocography</td>\n",
       "      <td>0.118510</td>\n",
       "      <td>0.028736</td>\n",
       "      <td>348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.112615</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.105882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>kr-vs-k</td>\n",
       "      <td>0.011957</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>11538</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.032694</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>9454</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>volcanoes-a1</td>\n",
       "      <td>0.060495</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>386</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.055765</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>35</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.020290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>wine-quality-white</td>\n",
       "      <td>0.064711</td>\n",
       "      <td>0.004482</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.062883</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>31</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.025316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>car-evaluation</td>\n",
       "      <td>0.104646</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>129</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>solar-flare</td>\n",
       "      <td>0.286649</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>10</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.057366</td>\n",
       "      <td>0.043796</td>\n",
       "      <td>133</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>allbp</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>728</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>allrep</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>728</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>dis</td>\n",
       "      <td>0.074980</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>728</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.060432</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>1549</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>car</td>\n",
       "      <td>0.123081</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089426</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>steel-plates-fault</td>\n",
       "      <td>0.122864</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>162</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.154031</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>43</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.056180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Dataset  IF Spearman Correlation  IF Jaccard Similarity  IF Number Flagged  IF Jaccard Similarity to top 10  IF Jaccard Similarity Given IQR  LOF Spearman Correlation  LOF Jaccard Similarity  LOF Number Flagged  LOF Jaccard Similarity to top 10  LOF Jaccard Similarity Given IQR\n",
       "0                            soybean                 0.192750               0.048387                185                         0.818182                         0.800000                  0.168080                0.123288                  72                          0.666667                          0.529412\n",
       "1                         micro-mass                 0.227214               0.074380                120                         0.538462                         0.538462                  0.211286                0.200000                  20                          0.333333                          0.500000\n",
       "2                     mfeat-karhunen                 0.121628               0.009756               1025                         0.666667                         0.700000                  0.126730                0.714286                  14                          1.000000                          0.625000\n",
       "3             Amazon_employee_access                 0.027099               0.002167               3689                         0.052632                         0.040541                  0.023831                0.000583               15441                          0.176471                          0.166667\n",
       "4                            abalone                 0.084646               0.047847                209                         1.000000                         1.000000                  0.098596                0.238095                  42                          1.000000                          0.045872\n",
       "5                             cnae-9                 0.142895               0.020455                439                         0.666667                         0.450000                  0.165895                0.059172                 169                          1.000000                          1.000000\n",
       "6                            semeion                 0.123180               0.019960                501                         0.333333                         0.300000                  0.119277                0.363636                   5                          0.250000                          0.200000\n",
       "7                            vehicle                 0.179932               0.375000                 23                         0.818182                         0.900000                  0.183321                0.236842                  37                          0.818182                          0.818182\n",
       "8                           satimage                 0.068252               0.006173               1620                         1.000000                         0.333333                  0.086692                0.263158                  38                          1.000000                          0.030211\n",
       "9             analcatdata_authorship                 0.187523               0.084746                118                         0.666667                         0.800000                  0.187748                0.833333                  12                          1.000000                          1.000000\n",
       "10                          breast-w                 0.205701               0.909091                 11                         1.000000                         0.900000                  0.192553                0.079365                 126                          0.062500                          0.270270\n",
       "11                       SpeedDating                 0.036947               0.001898               4212                         0.250000                         0.400000                  0.032445                0.010657                 559                          0.111111                          0.200000\n",
       "12                        eucalyptus                 0.200516               1.000000                 10                         1.000000                         1.000000                  0.200508                0.263158                  38                          1.000000                          0.500000\n",
       "13                            isolet                 0.007967               0.001785               2796                         0.111111                         0.100000                  0.065933                0.500000                   8                          0.428571                          0.023316\n",
       "14                       bioresponse                 0.078158               0.008654               1039                         0.538462                         0.013975                  0.048645                0.312500                  11                          0.333333                          0.076087\n",
       "15                             vowel                 0.172177               0.075188                133                         0.818182                         0.529412                  0.174367                0.082645                 121                          1.000000                          1.000000\n",
       "16             wall-robot-navigation                 0.074084               0.003979               2513                         1.000000                         0.526316                  0.099429                0.192308                  52                          0.818182                          0.034247\n",
       "17                   credit-approval                 0.206280               0.500000                 20                         0.666667                         0.727273                  0.201520                0.147541                  60                          0.818182                          0.900000\n",
       "18             artificial-characters                 0.054158               0.003019               3312                         1.000000                         0.900000                  0.092191                0.250000                  35                          0.900000                          0.027190\n",
       "19                            splice                 0.066489               0.009091                656                         0.214286                         0.272727                  0.077076                0.666667                  10                          0.666667                          0.666667\n",
       "20                               har                 0.044569               0.001061               8478                         0.818182                         0.081081                  0.062764                0.833333                  12                          1.000000                          0.023810\n",
       "21                               cmc                 0.092164               0.017032                408                         0.538462                         0.545455                  0.088880                0.013536                 589                          0.250000                          0.200000\n",
       "22                           segment                 0.095930               0.015306                587                         0.818182                         0.900000                  0.129091                0.232558                  43                          1.000000                          0.086207\n",
       "23                    JapaneseVowels                 0.043891               0.002404               3742                         0.818182                         0.900000                  0.073782                0.909091                  11                          1.000000                          0.014815\n",
       "24                               jm1                 0.052475               0.003519               2842                         1.000000                         0.666667                  0.076044                0.068493                 146                          0.000000                          0.011792\n",
       "25                         gas-drift                 0.032597               0.001470               5442                         0.666667                         0.222222                  0.101666                0.296296                  25                          0.666667                          0.042654\n",
       "26                          mushroom                 0.044329               0.002150               4186                         0.538462                         0.700000                  0.059980                0.421053                  17                          0.666667                          0.800000\n",
       "27                             irish                 0.188731               0.058824                152                         0.666667                         0.800000                  0.240584                0.149254                  67                          0.666667                          0.800000\n",
       "28                             profb                 0.209713               0.072993                137                         1.000000                         1.000000                  0.209710                0.101010                  99                          1.000000                          0.900000\n",
       "29                             adult                 0.020434               0.001377               6536                         0.538462                         0.142857                  0.007759                0.000330               18169                          0.052632                          0.090909\n",
       "30                            anneal                 0.159308               0.029316                306                         0.538462                         0.700000                  0.110357                0.090909                  86                          0.538462                          0.250000\n",
       "31                          credit-g                 0.108447               0.050955                155                         0.538462                         0.700000                  0.126817                0.125000                  53                          0.538462                          0.500000\n",
       "32  blood-transfusion-service-center                 0.138383               0.800000                  8                         0.666667                         0.800000                  0.197050                0.150943                  51                          0.727273                          0.307692\n",
       "33                  monks-problems-2                 0.216964               0.136986                 73                         0.666667                         0.300000                  0.228506                0.126582                  79                          1.000000                          1.000000\n",
       "34                       tic-tac-toe                 0.176036               0.714286                 14                         1.000000                         1.000000                  0.176037                0.322581                  31                          1.000000                          1.000000\n",
       "35                       qsar-biodeg                 0.167831               0.086207                116                         1.000000                         0.909091                  0.174712                0.131579                  76                          0.818182                          0.105263\n",
       "36                              wdbc                 0.227597               0.833333                 12                         1.000000                         1.000000                  0.162705                0.113208                  49                          0.428571                          0.461538\n",
       "37                           phoneme                 0.059565               0.008443               1065                         0.818182                         0.900000                  0.091841                0.140845                  71                          1.000000                          0.020040\n",
       "38                          diabetes                 0.157496               0.750000                 11                         0.818182                         0.900000                  0.188928                0.281250                  31                          0.818182                          0.900000\n",
       "39                   ozone-level-8hr                 0.091133               0.020179                445                         0.538462                         0.500000                  0.088677                0.300000                  29                          0.666667                          0.120000\n",
       "40                       hill-valley                 0.131258               0.123077                 63                         0.666667                         0.444444                  0.176629                0.285714                  35                          1.000000                          0.099010\n",
       "41                               kc2                 0.237648               1.000000                 10                         1.000000                         1.000000                  0.151531                0.105263                  74                          0.000000                          0.275862\n",
       "42                     eeg-eye-state                 0.044736               0.002779               3598                         1.000000                         0.476190                  0.056412                0.400000                  25                          1.000000                          0.019724\n",
       "43  climate-model-simulation-crashes                 0.186921               0.193548                 27                         0.428571                         0.500000                  0.058462                0.153846                   5                          0.111111                          0.200000\n",
       "44                          spambase                 0.080661               0.010163                984                         1.000000                         0.500000                  0.100461                0.236842                  37                          0.818182                          0.036232\n",
       "45                              ilpd                 0.224883               1.000000                 10                         1.000000                         1.000000                  0.224807                0.250000                  40                          0.818182                          0.833333\n",
       "46         one-hundred-plants-margin                 0.127380               0.035857                250                         0.818182                         0.818182                  0.137016                0.294118                  34                          1.000000                          0.322581\n",
       "47           banknote-authentication                 0.146491               0.391304                 22                         0.818182                         0.900000                  0.164772                0.294118                  34                          1.000000                          0.163934\n",
       "48                          mozilla4                 0.035138               0.004964               1812                         0.818182                         0.409091                  0.058773                0.112903                  59                          0.333333                          0.018735\n",
       "49                       electricity                 0.021894               0.000283              35377                         0.818182                         0.900000                  0.025757                0.000646               15472                          0.666667                          0.120482\n",
       "50                           madelon                 0.076949               0.005468               1645                         0.176471                         0.214286                  0.107298                1.000000                  10                          1.000000                          0.263158\n",
       "51                             scene                 0.084789               0.008658                922                         0.428571                         0.454545                  0.107430                0.011074                 903                          0.333333                          0.363636\n",
       "52                              musk                 0.066926               0.003582               2792                         0.818182                         0.900000                  0.079772                0.476190                  21                          1.000000                          0.028409\n",
       "53                             nomao                 0.018157               0.000394              22848                         0.176471                         0.071429                  0.028980                0.001389                7201                          0.000000                          0.002758\n",
       "54                    MagicTelescope                 0.039705               0.001714               5835                         1.000000                         0.217391                  0.055981                0.190476                  40                          0.666667                          0.019305\n",
       "55                  PhishingWebsites                 0.031073               0.001340               5969                         0.333333                         0.416667                  0.042719                0.001673                5377                          0.000000                          0.005848\n",
       "56                           nursery                 0.001390               0.000750              12001                         0.000000                         0.000000                  0.038221                0.002093                3821                          0.600000                          0.600000\n",
       "57                       page-blocks                 0.073969               0.089286                112                         1.000000                         0.833333                  0.091999                0.200000                  50                          1.000000                          0.028736\n",
       "58                       hypothyroid                 0.063677               0.006950               1149                         0.666667                         0.160000                  0.063338                0.095238                  82                          0.333333                          0.029963\n",
       "59                             yeast                 0.141702               0.083333                120                         1.000000                         1.000000                  0.140163                0.209302                  42                          0.818182                          0.562500\n",
       "60                             kropt                 0.017036               0.000591              13534                         0.111111                         0.100000                  0.032388                0.000891               11220                          0.818182                          0.800000\n",
       "61                  CreditCardSubset                 0.037584               0.007282               1235                         0.818182                         0.105882                  0.071029                0.094340                  48                          0.250000                          0.026403\n",
       "62                           shuttle                 0.022741               0.000271              36885                         1.000000                         0.004252                  0.022768                0.006369                1570                          1.000000                          0.188679\n",
       "63                         Satellite                 0.076107               0.008969               1115                         0.818182                         0.375000                  0.077430                0.303030                  33                          1.000000                          0.094340\n",
       "64                          baseball                 0.149023               0.117647                 85                         0.818182                         0.900000                  0.149068                0.322581                  31                          1.000000                          0.909091\n",
       "65                               mc1                 0.056310               0.012048                830                         1.000000                         0.322581                  0.146067                0.153846                  50                          0.117647                          0.125000\n",
       "66                               pc1                 0.163733               0.714286                 14                         1.000000                         1.000000                  0.151501                0.125000                  71                          0.818182                          0.059211\n",
       "67                  cardiotocography                 0.118510               0.028736                348                         1.000000                         0.833333                  0.112615                0.500000                  14                          0.666667                          0.105882\n",
       "68                           kr-vs-k                 0.011957               0.000520              11538                         0.111111                         0.200000                  0.032694                0.001058                9454                          1.000000                          0.900000\n",
       "69                      volcanoes-a1                 0.060495               0.020619                386                         0.666667                         0.800000                  0.055765                0.184211                  35                          0.583333                          0.020290\n",
       "70                wine-quality-white                 0.064711               0.004482               2007                         0.818182                         0.473684                  0.062883                0.205882                  31                          0.538462                          0.025316\n",
       "71                    car-evaluation                 0.104646               0.061069                129                         0.538462                         0.600000                  0.098480                0.800000                   8                          0.727273                          0.800000\n",
       "72                       solar-flare                 0.286649               0.818182                 10                         0.818182                         0.700000                  0.057366                0.043796                 133                          0.133333                          0.057143\n",
       "73                             allbp                 0.074980               0.012346                728                         0.428571                         0.157895                  0.060432                0.005158                1549                          0.428571                          0.400000\n",
       "74                            allrep                 0.074980               0.012346                728                         0.428571                         0.157895                  0.060432                0.005158                1549                          0.428571                          0.400000\n",
       "75                               dis                 0.074980               0.012346                728                         0.428571                         0.157895                  0.060432                0.005158                1549                          0.428571                          0.400000\n",
       "76                               car                 0.123081               0.008039               1244                         0.428571                         0.000000                  0.089426                0.013717                 729                          0.000000                          0.035088\n",
       "77                steel-plates-fault                 0.122864               0.061728                162                         0.818182                         0.750000                  0.154031                0.152174                  43                          0.428571                          0.056180"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This tests on all OpenML datasets listed above. In this case, we use\n",
    "# Isolation Forest as well as Local Outlier Factor (LOF). \n",
    "\n",
    "# As well as examining the spearman correlation and jaccard score \n",
    "# (for non-zero scores), we evaluate the detectors in two other ways.\n",
    "\n",
    "# 1) We take the top 10 scores for each detector on each dataset. \n",
    "# In this case, we know the doping process modified 10 rows, but this \n",
    "# information will not typically be available. As it can be difficult \n",
    "# with outlier detectors to determine the best cut-off, this test\n",
    "# is included to simulate where there is a reasonable guess as to the \n",
    "# number of outliers. It demonstrates that the detectors rank the scores\n",
    "# well such that those modified by the doping process tend to have the \n",
    "# highest scores, even if the ideal cutoff remains elusive. \n",
    "\n",
    "# 2) We use a common technique in outlier detection to determine a cutoff, \n",
    "# testing the set of outlier scores for extreme values, and taking any \n",
    "# unusually high scores as outliers. For this we calculate the \n",
    "# interquartile range, and use a coefficient of 2.2, which is standard \n",
    "# for IQR tests, on the IF scores. The LOF scores, however, are more \n",
    "# dispersed, and a coefficient of 22.0 was used instead. \n",
    "\n",
    "# This demonstrates that IF and LOF are both generally able to give higher\n",
    "# scores to modified rows after the doping process than before, and not \n",
    "# give higher scores to unmodified rows. \n",
    "\n",
    "# The numbers of rows flagged (meaning they recieved a higher score\n",
    "# after doping vs before) by both detectors is displayed. In some cases \n",
    "# the count is very high, but the actual increases in scores are trivial,\n",
    "# and so a good threshold is simply needed to establish a cutoff for \n",
    "# meaningful increases in score. \n",
    "\n",
    "# Where the number of outliers can be estimated,  both detectors tend\n",
    "# to do quite well, as seen between the high jaccard scores between \n",
    "# the top ten flagged rows and the actual modified rows flag. In many \n",
    "# cases IF does well and LOF poorly or vice versa, a common theme in outlier\n",
    "# detection where different detectors use different algorithms and are \n",
    "# able to identify different types of outliers.\n",
    "\n",
    "\n",
    "if_spearman_corr_arr = []\n",
    "if_jaccard_scores_arr = []\n",
    "if_num_flagged_arr = []\n",
    "if_jaccard_top_ten_arr = []\n",
    "if_jaccard_iqr_arr = []\n",
    "\n",
    "lof_spearman_corr_arr = []\n",
    "lof_jaccard_scores_arr = []\n",
    "lof_num_flagged_arr = []\n",
    "lof_jaccard_top_ten_arr = []\n",
    "lof_jaccard_iqr_arr = []\n",
    "\n",
    "for filename in real_files:\n",
    "    print(\"Evaluating\", filename)\n",
    "    data = fetch_openml(filename, version=1)\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    data_modifier = DopingOutliersTest()\n",
    "    df_modified, outlier_scores = data_modifier.transform(df, random_state=0, verbose=False)\n",
    "    if df_modified is None:\n",
    "        # The doping process may return None if there are invalid parameters or too few\n",
    "        # columns remaining after removing high-cardinality categorical columns from the\n",
    "        # doping process. \n",
    "        print(\"Doping process returned None. Skipping this file.\")\n",
    "        continue\n",
    "\n",
    "    # Encode the original data\n",
    "    df_encoded = get_count_encoding(df)\n",
    "    df_encoded = df_encoded.fillna(0)\n",
    "    df_encoded = df_encoded.replace([np.nan, -np.nan], 0)\n",
    "    \n",
    "    # Get IF scores on original data\n",
    "    det = IsolationForest(random_state=0)\n",
    "    det.fit(df_encoded)\n",
    "    y_orig_if = det.score_samples(df_encoded)\n",
    "\n",
    "    # Get LOF scores on original data   \n",
    "    det = LocalOutlierFactor(novelty=True)\n",
    "    det.fit(df_encoded)\n",
    "    y_orig_lof = det.score_samples(df_encoded)\n",
    "    \n",
    "    # Encode the modified data\n",
    "    df_modified_encoded = get_count_encoding(df_modified)\n",
    "    df_modified_encoded = df_modified_encoded.fillna(0)\n",
    "    df_modified_encoded = df_modified_encoded.replace([np.nan, -np.nan], 0)\n",
    "    \n",
    "    # Get IF scores on the modified dataset\n",
    "    det = IsolationForest(random_state=0)\n",
    "    det.fit(df_modified_encoded)\n",
    "    y_modified_if = det.score_samples(df_modified_encoded)\n",
    "\n",
    "    # Get LOF scores on the modified data   \n",
    "    det = LocalOutlierFactor(novelty=True)\n",
    "    det.fit(df_modified_encoded)\n",
    "    y_modified_lof = det.score_samples(df_modified_encoded)\n",
    "    \n",
    "    # Store the IF results\n",
    "    df_modified['IF Orig Score'] = y_orig_if * (-1)\n",
    "    df_modified['IF Modified Score'] = y_modified_if * (-1)\n",
    "    df_modified['IF Gain'] = df_modified['IF Modified Score'] - df_modified['IF Orig Score']\n",
    "    \n",
    "    # Store the LOF results\n",
    "    df_modified['LOF Orig Score'] = y_orig_lof * (-1)\n",
    "    df_modified['LOF Modified Score'] = y_modified_lof * (-1)\n",
    "    df_modified['LOF Gain'] = df_modified['LOF Modified Score'] - df_modified['LOF Orig Score']\n",
    "\n",
    "    # Get the top 10 IF scores\n",
    "    top_ten_if = sorted(df_modified['IF Gain'], reverse=True)[10]\n",
    "    df_modified['IF Gain Top 10'] = df_modified['IF Gain'] > top_ten_if\n",
    "\n",
    "    # Get the top 10 LOF scores\n",
    "    top_ten_lof = sorted(df_modified['LOF Gain'], reverse=True)[10]\n",
    "    df_modified['LOF Gain Top 10'] = df_modified['LOF Gain'] > top_ten_lof\n",
    "    \n",
    "    # Get the IF scores with high IQR values\n",
    "    q1 = df_modified['IF Gain'].quantile(0.25)\n",
    "    q3 = df_modified['IF Gain'].quantile(0.75)\n",
    "    iqr_threshold = q3 + 2.2 * (q3 - q1)\n",
    "    df_modified['IF Gain High IQR'] = df_modified['IF Gain'] > iqr_threshold\n",
    "    \n",
    "    # Get the LOF scores with high IQR values\n",
    "    q1 = df_modified['LOF Gain'].quantile(0.25)\n",
    "    q3 = df_modified['LOF Gain'].quantile(0.75)\n",
    "    iqr_threshold = q3 + 22.0 * (q3 - q1)\n",
    "    df_modified['LOF Gain High IQR'] = df_modified['LOF Gain'] > iqr_threshold\n",
    "\n",
    "    # Store the outlier score estimated by the doping tool\n",
    "    df_modified['OUTLIER SCORE'] = outlier_scores\n",
    "\n",
    "    # Add binary columns indicating if IF and the Doping process identified the rows\n",
    "    # with any score\n",
    "    df_modified['IF Flagged'] = df_modified['IF Gain'] > 0\n",
    "    df_modified['LOF Flagged'] = df_modified['LOF Gain'] > 0.01\n",
    "    df_modified['Doping Flagged'] = df_modified['OUTLIER SCORE'] > 0    \n",
    "        \n",
    "    # IF \n",
    "    spearman_corr = scipy.stats.spearmanr(df_modified['IF Gain'], df_modified['OUTLIER SCORE'])[0]\n",
    "    if spearman_corr !=  spearman_corr:\n",
    "        spearman_corr = 0.0\n",
    "    if_spearman_corr_arr.append(spearman_corr)\n",
    "    \n",
    "    jaccard_sim = jaccard_score(df_modified['IF Flagged'], df_modified['Doping Flagged'])\n",
    "    if_jaccard_scores_arr.append(jaccard_sim)\n",
    "    \n",
    "    if_num_flagged = df_modified['IF Flagged'].sum()\n",
    "    if_num_flagged_arr.append(if_num_flagged)\n",
    "\n",
    "    jaccard_sim = jaccard_score(df_modified['IF Gain Top 10'], df_modified['Doping Flagged'])\n",
    "    if_jaccard_top_ten_arr.append(jaccard_sim)   \n",
    "\n",
    "    jaccard_sim = jaccard_score(df_modified['IF Gain High IQR'], df_modified['Doping Flagged'])\n",
    "    if_jaccard_iqr_arr.append(jaccard_sim)\n",
    "    \n",
    "    # LOF\n",
    "    spearman_corr = scipy.stats.spearmanr(df_modified['LOF Gain'], df_modified['OUTLIER SCORE'])[0]\n",
    "    if spearman_corr !=  spearman_corr:\n",
    "        spearman_corr = 0.0\n",
    "    lof_spearman_corr_arr.append(spearman_corr)\n",
    "    \n",
    "    jaccard_sim = jaccard_score(df_modified['LOF Flagged'], df_modified['Doping Flagged'])\n",
    "    lof_jaccard_scores_arr.append(jaccard_sim)\n",
    "    \n",
    "    lof_num_flagged = df_modified['LOF Flagged'].sum()\n",
    "    lof_num_flagged_arr.append(lof_num_flagged)\n",
    "    \n",
    "    jaccard_sim = jaccard_score(df_modified['LOF Gain Top 10'], df_modified['Doping Flagged'])\n",
    "    lof_jaccard_top_ten_arr.append(jaccard_sim)\n",
    "    \n",
    "    jaccard_sim = jaccard_score(df_modified['LOF Gain High IQR'], df_modified['Doping Flagged'])\n",
    "    lof_jaccard_iqr_arr.append(jaccard_sim)\n",
    "    \n",
    "results_df = pd.DataFrame({\n",
    "    \"Dataset\": real_files, \n",
    "    \n",
    "    \"IF Spearman Correlation\": if_spearman_corr_arr,\n",
    "    \"IF Jaccard Similarity\": if_jaccard_scores_arr,\n",
    "    \"IF Number Flagged\": if_num_flagged_arr,\n",
    "    \"IF Jaccard Similarity to top 10\": if_jaccard_top_ten_arr,\n",
    "    \"IF Jaccard Similarity Given IQR\": if_jaccard_iqr_arr,\n",
    "\n",
    "    \"LOF Spearman Correlation\": lof_spearman_corr_arr,\n",
    "    \"LOF Jaccard Similarity\": lof_jaccard_scores_arr,\n",
    "    \"LOF Number Flagged\": lof_num_flagged_arr,\n",
    "    \"LOF Jaccard Similarity to top 10\": lof_jaccard_top_ten_arr,\n",
    "    \"LOF Jaccard Similarity Given IQR\": lof_jaccard_iqr_arr,    \n",
    "})\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ff1616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IF Jaccard Similarity to top 10: 0.6944388303342818\n"
     ]
    }
   ],
   "source": [
    "print(\"Average IF Jaccard Similarity to top 10:\", results_df['IF Jaccard Similarity to top 10'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f5e16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average LOF Jaccard Similarity to top 10: 0.6421536103171612\n"
     ]
    }
   ],
   "source": [
    "print(\"Average LOF Jaccard Similarity to top 10:\", results_df['LOF Jaccard Similarity to top 10'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c146b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average IF Jaccard Similarity using IQR: 0.5609408440365509\n"
     ]
    }
   ],
   "source": [
    "print(\"Average IF Jaccard Similarity using IQR:\", results_df['IF Jaccard Similarity Given IQR'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18c982dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average LOF Jaccard Similarity using IQR: 0.32877780387880173\n"
     ]
    }
   ],
   "source": [
    "print(\"Average LOF Jaccard Similarity using IQR:\", results_df['LOF Jaccard Similarity Given IQR'].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
