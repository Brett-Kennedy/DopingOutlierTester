{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f596e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OutliersTest' from 'outliers_test' (C:\\python_projects\\Doping_project\\examples\\..\\outliers_test.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23168/2717205056.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"..\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0moutliers_test\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutliersTest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'OutliersTest' from 'outliers_test' (C:\\python_projects\\Doping_project\\examples\\..\\outliers_test.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from outliers_test import DopingOutliersTest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c9b656",
   "metadata": {},
   "source": [
    "### Collect a dataset from OpenML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7850a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml('breast-w', version=1)\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18ea90",
   "metadata": {},
   "source": [
    "### Use Doping Outliers Test to tranform the data into a format with known outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modifier = OutliersTest()\n",
    "df_modified = data_modifier.transform(df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc7755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip out the estimated outlier scores from df_modified\n",
    "outlier_scores = df_modified['OUTLIER SCORE']\n",
    "df_modified = df_modified.drop(columns=['OUTLIER SCORE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1b3908",
   "metadata": {},
   "source": [
    "### Function to provide Count Encoding for categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b662485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example uses Isolation Forest which works strictly with numeric values,\n",
    "# requiring all categorical values to be either dropped or encoded. There\n",
    "# are many possible encoders, such as one-hot, label etc, but Count Encoding\n",
    "# tends to work well with outlier detection. Count Encoding is available in \n",
    "# python modules, but to minimize pip installs, and as it is very simple, it \n",
    "# is provided here.\n",
    "\n",
    "def get_count_encoding(df):\n",
    "    df = df.copy()\n",
    "    for col_name in df.columns:\n",
    "        if df[col_name].dtype.name in ['str', 'category', 'object']:\n",
    "            df[col_name] = df[col_name].astype(str)\n",
    "            vc = df[col_name].value_counts(dropna=False)\n",
    "            df[col_name] = df[col_name].replace([None, np.nan, -np.nan, 'nan'], df[col_name].mode()[0])\n",
    "            map_dict = {x: y for x, y in zip(vc.index, vc.values)}\n",
    "            df[col_name] = df[col_name].map(map_dict)\n",
    "            df[col_name] = df[col_name].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656e8cc",
   "metadata": {},
   "source": [
    "### Get IsolationForest (IF) scores on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57effc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first encode the data in a format suitable for IF\n",
    "df_encoded = get_count_encoding(df)\n",
    "df_encoded = df_encoded.fillna(0)\n",
    "df_encoded = df_encoded.replace([np.nan, -np.nan], 0)\n",
    "\n",
    "det = IsolationForest(random_state=0)\n",
    "det.fit(df_encoded)\n",
    "y_orig_if = det.score_samples(df_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa9f5de",
   "metadata": {},
   "source": [
    "### Get IF scores on the modified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73936fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified_encoded = get_count_encoding(df_modified)\n",
    "df_modified_encoded = df_modified_encoded.fillna(0)\n",
    "df_modified_encoded = df_modified_encoded.replace([np.nan, -np.nan], 0)\n",
    "\n",
    "det = IsolationForest(random_state=0)\n",
    "det.fit(df_modified_encoded)\n",
    "y_modified_if = det.score_samples(df_modified_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aee587",
   "metadata": {},
   "source": [
    "### Examine and compare the IF Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3ed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Doping Outliers Test tool cannot estimate how unusual any row is, \n",
    "# only how unusual it likely is compared to its state before the doping\n",
    "# process. As such, to evaluate how well IF does in identifying the modified\n",
    "# rows, we get the IF score of each row before and after the doping process\n",
    "# and examine the difference in IF scores.\n",
    "\n",
    "# As IF is known to be a strong outlier detector, the gains in outlier scores\n",
    "# for the modified rows should be higher than for the unmodified rows, which\n",
    "# is, in fact, the case. \n",
    "\n",
    "# IF gives more negative scores to more anomalous rows. To examine the outlierness\n",
    "# of each row in positive terms, we multiply each score by -1.\n",
    "\n",
    "# IF tends to give inexact score to rows not likely to be outliers, so any scores \n",
    "# below 0.5 are reduced to 0.0, indicating an inlier. \n",
    "\n",
    "df_modified['IF Orig Score'] = y_orig_if * (-1)\n",
    "df_modified['IF Orig Cleaned'] = df_modified['IF Orig Score'].apply(lambda x: 0 if x <= 0.5 else x)\n",
    "df_modified['IF Modified Score'] = y_modified_if * (-1)\n",
    "df_modified['IF Modified Cleaned'] = df_modified['IF Modified Score'].apply(lambda x: 0 if x <= 0.5 else x)\n",
    "df_modified['IF Gain'] = df_modified['IF Modified Cleaned'] - df_modified['IF Orig Cleaned']\n",
    "df_modified['IF Gain Cleaned'] = df_modified['IF Gain'].apply(lambda x: 0 if x <= 0.0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b71aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the outlier score estimated by the doping tool\n",
    "df_modified['OUTLIER SCORE'] = outlier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379195ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the correlations\n",
    "\n",
    "# The scores on the original and modified datasets are very similar, as only a small number of\n",
    "# rows were modified. However, they are different.\n",
    "print(\"Pearson Correlation Orig to Modified IF scores: \",\n",
    "      scipy.stats.spearmanr(df_modified['IF Orig Cleaned'], df_modified['IF Modified Cleaned'])[0])\n",
    "\n",
    "# The IF scores (once cleaned) correlate very closely with the estimated scores produced by \n",
    "# the Doping Outlier Tester tool.\n",
    "print(\"Pearson Correlation Gain IF scores to Estimated Scores: \",\n",
    "      scipy.stats.spearmanr(df_modified['IF Gain Cleaned'], df_modified['OUTLIER SCORE'])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e7d3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This plots the scores. It can be seen the y are well correlated, \n",
    "# though the scores from the isolation forest are not completely \n",
    "# monotonically related to the estimated scores from the Doping \n",
    "# Outlier Tester, as expected, as the Doping Outlier Detector can\n",
    "# not estimate accurately how much more unusual a modified row will be \n",
    "# considered by any given outlier detector. \n",
    "\n",
    "df_modified = df_modified.sort_values(['OUTLIER SCORE'])\n",
    "df_modified = df_modified.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=False, figsize=(7,5))\n",
    "s = sns.lineplot(x=df_modified.index, y=df_modified['IF Gain Cleaned'], color='blue', ax=ax[0])\n",
    "s = sns.lineplot(x=df_modified.index, y=df_modified['OUTLIER SCORE'], color='red', ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eca4139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the specific gain in IF score and estimate outlier score\n",
    "# for the 10 rows modified as well as 10 other rows. We see both\n",
    "# are non-zero in the same rows. This is not strictly true for\n",
    "# all datasets, but tends to be the case. \n",
    "\n",
    "df_modified[['IF Gain Cleaned', 'OUTLIER SCORE']].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d3082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
